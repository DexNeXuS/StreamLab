; ─────────────────────────────────────────────────────────────
; OLLAMA Chat Bot — INI config (for run_ini.cs)
; Use {message} in task for the user's message. Use \n for newlines in multiline values.
; Path: pass this file path as the "iniPath" argument in Streamer.bot (with or without quotes).
; ─────────────────────────────────────────────────────────────

[Model]
; Ollama model name (e.g. mistral, llama3.2, llama3)
model = mistral
; System prompt: how the bot "is". Keep short for 7B–13B models.
personality = You are a sarcastic but actually helpful Twitch chatbot. You love memes and banter, but you prioritize being useful when someone asks a real question or uses a command.
; Instructions for each reply. Use {message} where the user's message should go.
task = TASK:\n- Reply in Twitch chat as the bot.\n- Always follow the user's intent first: answer questions directly, execute !commands helpfully, give clear info when asked.\n- Keep replies to 1-2 short sentences maximum (or 3 if they clearly want detail).\n- Casual, witty, slightly sarcastic Twitch tone. Memes and light roasting are fine when it fits.\n- Never mention rules, context, usernames, or that you're an AI.\n- Never repeat the user's message.\n- Start your reply directly — no "Here's my response" or roleplay fluff.\n\nUSER MESSAGE:\n{message}\n\nREPLY:
; Rules so the bot follows questions and !commands instead of defaulting to sarcasm.
commandRules = Prioritize following the user's intent exactly.\n- If it's a question → answer directly and clearly.\n- If the message starts with ! → treat it as a command and respond helpfully + concisely.\n- If they ask for information, lists, or explanations → be useful first, funny second.\n- Only be sarcastic when it doesn't get in the way of what they actually want.\n- If you're unsure what they want, reply with a short clarifying question.
; Extra rules appended to the hardcoded system rules. Optional.
extraRules =

[Streamer]
; Private facts about the streamer. Only used when someone asks about the streamer (e.g. "who is Dex?").
streamerInfo =

[Lists]
; Usernames the bot will never reply to. Comma or newline (\n) separated. Lines starting with ; or # are ignored.
ignoreList = NeXuS_B_o_T_, nexus_b_o_t_
; VIPs / usernames that always get a reply chance (ignore the reply % below).
priorityList =

[Chance]
; 0–100. Chance to reply to a message. Priority list users are not affected.
replyChancePercent = 100

[ResponseStyle]
; 1, 2, or 3. Max sentences per reply.
maxSentences = 2
; true/false. Whether the bot may use emojis.
allowEmojis = true
; None = helpful only. Light = witty when it fits. Full = sarcastic Twitch vibe.
sarcasmLevel = Light
; true/false. Prepend @username to every reply.
mentionUser = false

[Generation]
; 0–2 (e.g. 0.8). Higher = more random. Typical 0.75–0.85 for chat.
temperature = 0.8
; 0.5–1 (e.g. 0.9). Nucleus sampling.
topP = 0.9
; Max reply length in tokens. 80–300 typical.
numPredict = 150
; 1.0–2.0 (e.g. 1.1). Discourages repetition.
repeatPenalty = 1.1
; 0–1. Discourages already-mentioned topics. 0 = off.
presencePenalty = 0
; 0–1. Discourages word repetition. 0 = off.
frequencyPenalty = 0
; Extra stop sequences, one per line or comma-separated. Added to defaults.
stopSequences =

[Tweaks]
; Prepended to every reply (e.g. " LUL " or " hehe "). Optional.
forcedPrefix =
; true/false. When true, saves OLLAMA_LastPrompt, OLLAMA_LastSystem, OLLAMA_RawResponse, OLLAMA_LastReply to globals for debugging.
debugMode = false
; true/false. When true, last 2 user+bot exchanges are added to the prompt for context. Best with 13B+ models.
shortMemory = false
; Min seconds between replies to the same user. 0 = disabled. Prevents spam loops.
rateLimitSeconds = 0
